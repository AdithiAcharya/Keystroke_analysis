{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13658519",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input, GRU, Dense, RepeatVector, TimeDistributed, Concatenate\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, RepeatVector, TimeDistributed, Concatenate\n",
    "\n",
    "# Paste the entire data as a string (replace with actual data)\n",
    "data_str= pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\Keystroke_analysis\\KeystrokeLoggingApplication\\src\\Keystrokes.csv\", on_bad_lines='skip')\n",
    "data.head()\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(StringIO(data_str))\n",
    "\n",
    "# Preprocess\n",
    "le = LabelEncoder()\n",
    "df['Target'] = le.fit_transform(df['Target'])  # Genuine -> 1, Imposter -> 0\n",
    "\n",
    "X = df.iloc[:, 1:32].values  # Features (timings)\n",
    "y = df['Target'].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# 2. Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# 3. TimeNet-like Model (GRU Autoencoder for Embeddings + Classifier)\n",
    "# Reshape for RNN: (samples, timesteps, features) - here timesteps=31, features=1 (univariate)\n",
    "X_train_resh = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_resh = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Define TimeNet Autoencoder\n",
    "def build_timenet_autoencoder(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder: 3 GRUs with 60 units each\n",
    "    e1 = GRU(60, return_sequences=True)(input_layer)\n",
    "    e2 = GRU(60, return_sequences=True)(e1)\n",
    "    encoded = GRU(60, return_sequences=False)(e2)  # Final hidden state as embedding\n",
    "\n",
    "    # Decoder: Repeat and reverse to reconstruct\n",
    "    decoded = RepeatVector(input_shape[0])(encoded)\n",
    "    d1 = GRU(60, return_sequences=True)(decoded)\n",
    "    d2 = GRU(60, return_sequences=True)(d1)\n",
    "    decoded = GRU(60, return_sequences=True)(d2)\n",
    "    output_layer = TimeDistributed(Dense(1))(decoded)  # Output reconstruction\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return autoencoder, Model(inputs=input_layer, outputs=encoded)  # Return autoencoder and encoder\n",
    "\n",
    "input_shape = (31, 1)  # 31 timings, 1 feature\n",
    "autoencoder, encoder = build_timenet_autoencoder(input_shape)\n",
    "\n",
    "# Train autoencoder (unsupervised on all X)\n",
    "X_resh = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "autoencoder.fit(X_resh, X_resh, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Extract embeddings\n",
    "embed_train = encoder.predict(X_train_resh)\n",
    "embed_test = encoder.predict(X_test_resh)\n",
    "\n",
    "# Train KNN on embeddings\n",
    "knn_time = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_time.fit(embed_train, y_train)\n",
    "y_pred_time_knn = knn_time.predict(embed_test)\n",
    "print(\"TimeNet + KNN Accuracy:\", accuracy_score(y_test, y_pred_time_knn))\n",
    "print(classification_report(y_test, y_pred_time_knn))\n",
    "\n",
    "# Train LR on embeddings\n",
    "lr_time = LogisticRegression(max_iter=1000)\n",
    "lr_time.fit(embed_train, y_train)\n",
    "y_pred_time_lr = lr_time.predict(embed_test)\n",
    "print(\"TimeNet + LR Accuracy:\", accuracy_score(y_test, y_pred_time_lr))\n",
    "print(classification_report(y_test, y_pred_time_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1412f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
